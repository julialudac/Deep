{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 : Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_imagenet = torchvision.datasets.ImageFolder('start_deep/start_deep/start_deep/train_images/', transform=data_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_imagenet, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "test_imagenet = torchvision.datasets.ImageFolder('start_deep/start_deep/start_deep/test_images/', transform=data_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_imagenet, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.6549, -0.7725, -0.9059,  ...,  0.2471,  0.2706,  0.2078],\n",
      "         [-0.8275, -0.8588, -0.8118,  ...,  0.2941,  0.2784,  0.2157],\n",
      "         [-0.7176, -0.7098, -0.7176,  ...,  0.2000,  0.2000,  0.2314],\n",
      "         ...,\n",
      "         [-0.4980, -0.7176, -0.8510,  ..., -0.8118, -0.7725, -0.7569],\n",
      "         [-0.7176, -0.7333, -0.6706,  ..., -0.4667, -0.5529, -0.6078],\n",
      "         [-0.1059,  0.1373,  0.2235,  ...,  0.2627,  0.2471,  0.2078]],\n",
      "\n",
      "        [[ 0.1725,  0.1137,  0.0471,  ...,  0.6235,  0.6353,  0.6039],\n",
      "         [ 0.0863,  0.0706,  0.0941,  ...,  0.6471,  0.6392,  0.6078],\n",
      "         [ 0.1412,  0.1451,  0.1412,  ...,  0.6000,  0.6000,  0.6157],\n",
      "         ...,\n",
      "         [ 0.2510,  0.1412,  0.0745,  ...,  0.0941,  0.1137,  0.1216],\n",
      "         [ 0.1412,  0.1333,  0.1647,  ...,  0.2667,  0.2235,  0.1961],\n",
      "         [ 0.4471,  0.5686,  0.6118,  ...,  0.6314,  0.6235,  0.6039]],\n",
      "\n",
      "        [[ 0.1725,  0.1137,  0.0471,  ...,  0.6235,  0.6353,  0.6039],\n",
      "         [ 0.0863,  0.0706,  0.0941,  ...,  0.6471,  0.6392,  0.6078],\n",
      "         [ 0.1412,  0.1451,  0.1412,  ...,  0.6000,  0.6000,  0.6157],\n",
      "         ...,\n",
      "         [ 0.2510,  0.1412,  0.0745,  ...,  0.0941,  0.1137,  0.1216],\n",
      "         [ 0.1412,  0.1333,  0.1647,  ...,  0.2667,  0.2235,  0.1961],\n",
      "         [ 0.4471,  0.5686,  0.6118,  ...,  0.6314,  0.6235,  0.6039]]]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(train_imagenet.__getitem__(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.9451, -0.9529, -0.9608,  ..., -0.9216, -0.9451, -0.9294],\n",
      "         [-0.9529, -0.9529, -0.9373,  ..., -0.8902, -0.9451, -0.9373],\n",
      "         [-0.9373, -0.9451, -0.8902,  ..., -0.8510, -0.9373, -0.9529],\n",
      "         ...,\n",
      "         [ 0.9686,  0.8510,  0.9294,  ...,  0.9922,  0.8980,  0.8275],\n",
      "         [ 0.9294,  0.8824,  1.0000,  ...,  0.3333,  0.7333,  0.7020],\n",
      "         [ 0.9451,  0.8196,  0.9137,  ..., -0.3098,  0.8196,  0.7725]],\n",
      "\n",
      "        [[ 0.0275,  0.0235,  0.0196,  ...,  0.0392,  0.0275,  0.0353],\n",
      "         [ 0.0235,  0.0235,  0.0314,  ...,  0.0549,  0.0275,  0.0314],\n",
      "         [ 0.0314,  0.0275,  0.0549,  ...,  0.0745,  0.0314,  0.0235],\n",
      "         ...,\n",
      "         [ 0.9843,  0.9255,  0.9647,  ...,  0.9961,  0.9490,  0.9137],\n",
      "         [ 0.9647,  0.9412,  1.0000,  ...,  0.6667,  0.8667,  0.8510],\n",
      "         [ 0.9725,  0.9098,  0.9569,  ...,  0.3451,  0.9098,  0.8863]],\n",
      "\n",
      "        [[ 0.0275,  0.0235,  0.0196,  ...,  0.0392,  0.0275,  0.0353],\n",
      "         [ 0.0235,  0.0235,  0.0314,  ...,  0.0549,  0.0275,  0.0314],\n",
      "         [ 0.0314,  0.0275,  0.0549,  ...,  0.0745,  0.0314,  0.0235],\n",
      "         ...,\n",
      "         [ 0.9843,  0.9255,  0.9647,  ...,  0.9961,  0.9490,  0.9137],\n",
      "         [ 0.9647,  0.9412,  1.0000,  ...,  0.6667,  0.8667,  0.8510],\n",
      "         [ 0.9725,  0.9098,  0.9569,  ...,  0.3451,  0.9098,  0.8863]]]), 2)\n"
     ]
    }
   ],
   "source": [
    "print(test_imagenet.__getitem__(7625))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 87117\n",
      "    Root Location: start_deep/start_deep/start_deep/train_images/\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.5,), std=(0.5,))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "print(train_imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x00000152204AA128>\n"
     ]
    }
   ],
   "source": [
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 7628\n",
      "    Root Location: start_deep/start_deep/start_deep/test_images/\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.5,), std=(0.5,))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "print(test_imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x0000015226D72F60>\n"
     ]
    }
   ],
   "source": [
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 : Define neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batc\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 : Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4 : Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.654\n",
      "[1,  4000] loss: 0.643\n",
      "[1,  6000] loss: 0.622\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5 : Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "classes = (0,1,)\n",
    "            \n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
